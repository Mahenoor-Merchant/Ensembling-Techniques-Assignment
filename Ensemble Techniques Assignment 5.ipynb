{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7029897c-f6e7-4bf5-84fc-7faf66eb719e",
   "metadata": {},
   "source": [
    "# Ensemble Techniques Assignment 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d1ba5f-10d4-419c-8238-ef7e4281367b",
   "metadata": {},
   "source": [
    "Q1. You are working on a machine learning project where you have a dataset containing numerical and categorical features. You have identified that some of the features are highly correlated, and there are missing values in some of the columns. You want to build a pipeline that automates the feature engineering process and handles the missing values.\n",
    "\n",
    "Design a pipeline that includes the following steps:\n",
    "\n",
    "Use an automated feature selection method to identify the important features in the dataset.\n",
    "\n",
    "Create a numerical pipeline that includes the following steps:\n",
    "* Impute the missing values in the numerical columns using the mean of the column values.\n",
    "* Scale the numerical columns using standardization.\n",
    "* Create a categorical pipeline that includes the following steps:\n",
    "* Impute the missing values in the categorical columns using the most frequent value of the column.\n",
    "* One-hot encode the categorical columns.\n",
    "* Combine the numerical and categorical pipelines using a ColumnTransformer.\n",
    "* Use a Random Forest Classifier to build the final model.\n",
    "* Evaluate the accuracy of the model on the test dataset.\n",
    "Note! Your solution should include code snippets for each step of the pipeline and a brief explanation of each step. You should also provide an interpretation of the results and suggest possible improvements for the pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7325b2d5-e832-469c-8dab-3ff6a53d4d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df = sns.load_dataset('tips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cc1a428-a6e4-446f-a2a3-a6cb86e08f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_bill     float64\n",
       "tip            float64\n",
       "sex           category\n",
       "smoker        category\n",
       "day           category\n",
       "time          category\n",
       "size             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "439350c8-27e6-4af6-a90a-86f1c6ec6ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols=['total_bill','tip','size']\n",
    "cat_cols=['sex','smoker','day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b228499-38d9-4cc5-af34-2760e9a08572",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('time',axis=1)\n",
    "y = df.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da50eb5a-a0de-4651-9221-27e086db31db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##importing necessary libraries as asked in the question for numerical columns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "##importing necessary libraries as asked in the question for categorical columns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "##importing RandomForestClassifier for training the model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "## importing Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "## Create a Pipeline for numerical columns\n",
    "# Applying SimpleImputer with mean Strategy and StandardScaler\n",
    "num_pipe=Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "\n",
    "## Create a Pipeline for categorical columns\n",
    "# Applying SimpleImputer with 'most frequent' startegy and OneHotEncoder\n",
    "cat_pipe=Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder())\n",
    "])\n",
    "\n",
    "## Transforming using the ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('numeric_columns',num_pipe,num_cols),\n",
    "    ('categorical_columns',cat_pipe,cat_cols)\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe1bcfd3-4b31-42c0-829d-07a5febc9232",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "973b398c-d2dd-46f5-9999-74bd19e1ff6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=preprocessor.fit_transform(X_train)\n",
    "X_test=preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47850cea-c900-42bf-8714-8d6cd7ce4d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c8464a4-6de4-4d5b-94bc-d6d4761cdbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82e085ca-66a7-45f7-a15e-2efcb1e3fcfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9753086419753086"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0077460-2d2d-4049-95a3-4fdc803c98ae",
   "metadata": {},
   "source": [
    "### Q2. Build a pipeline that includes a random forest classifier and a logistic regression classifier, and the use a voting classifier to combine their predictions. Train the pipeline on the iris dataset and evaluate its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df658b04-985e-4085-a2b8-90644b7bad43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the pipeline is: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('rf', RandomForestClassifier()),\n",
    "    ('lr', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Create the voting classifier\n",
    "voting_classifier = VotingClassifier(estimators=[('rf', pipeline[0]), ('lr', pipeline[1])], voting='soft')\n",
    "\n",
    "# Train  the pipeline on the iris dataset\n",
    "iris = sns.load_dataset('iris')\n",
    "X = iris.drop('species', axis=1)\n",
    "y = iris['species']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the accuracy of the pipeline\n",
    "accuracy = voting_classifier.score(X_test, y_test)\n",
    "\n",
    "print('The accuracy of the pipeline is:', accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6db0dd3-fbc7-4d5b-b9ab-1c72000a85ec",
   "metadata": {},
   "source": [
    "## The End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
